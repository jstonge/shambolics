[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "shambolics",
    "section": "",
    "text": "This model describes behaviors that require institutional strength to get off the ground. But as you add institutional levels to your collective, there is a cost. The model finds organizational free-riding, with some organizations preferring others to pay the cost of institutional strength while benefiting the behaviors emerging from those.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\n\n\n\nThis model describes the dilemma of learning to code in research groups when the cost of learning to code depends on the relative number of coders and non-coders in the group.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\nPreliminary results from a survey on the cost and benefits of learning to code\n\n\n\n\nSurvey\n\n\nProgramming\n\n\n\n\nThe costs and benefits of learning to code in science vary across individuals and disciplines. We should have a better idea of these tradeoffs before selling anyone on coding.\n\n\n\n\n\n\nNov 27, 2022\n\n\nJonathan St-Onge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreliminary modeling of a survey on the cost and benefits of learning to code\n\n\n\n\nSurvey\n\n\nProgramming\n\n\nModeling\n\n\n\n\nThe costs and benefits of learning to code in science vary across individuals and disciplines. We should have a better idea of these tradeoffs before selling anyone on coding.\n\n\n\n\n\n\nNov 27, 2022\n\n\nJonathan St-Onge\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nCDAE\n\n\nInteractive\n\n\n\n\nStatistics is hard. Computational statistics makes it a bit better.\n\n\n\n\n\n\nNov 27, 2022\n\n\nJonathan St-Onge\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/survey-programming/index.html",
    "href": "posts/survey-programming/index.html",
    "title": "Survey results (early release)",
    "section": "",
    "text": "pdata = FileAttachment(\"data_clean.csv\").csv({ typed: true })\n\n// useful vars\ncolnames = d3.sort(Object.keys(pdata[0]))\ncoders = pdata.filter(d => d.is_coder === 'coder')\nnon_coders = pdata.filter(d => d.is_coder === 'non coder')\ncoder_count = tidy(pdata, count(\"is_coder\")).map(d => d.n)\n\n// global filtering\nfiltered_dat = sel_dept == \"\" ? pdata : pdata.filter(d => d[\"dept_students_lab\"] === sel_dept)\nfiltered_coders = sel_dept == \"\" ? coders : coders.filter(d => d[\"dept_students_lab\"] === sel_dept)\nWe currently have  valid responses, from  different departments. There are  coders and  non-coders."
  },
  {
    "objectID": "posts/survey-programming/index.html#profiles",
    "href": "posts/survey-programming/index.html#profiles",
    "title": "Survey results (early release)",
    "section": "Profiles",
    "text": "Profiles\n\nviewof sel_dept = Inputs.select([''].concat(\n  tidy(\n    pdata.filter(d => d[\"dept_students_lab\"] !== null),\n    distinct('dept_students_lab')\n  ).map(d => d[\"dept_students_lab\"])), {label: \"Choose dept\"})\n\nviewof do_pct = Inputs.toggle({label: \"Show %\"}) \nviewof rm_nulls = Inputs.toggle({label: \"Remove nulls\", value: true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemographicsDev ProfilesTablesProfile DataQuestions\n\n\n\ncol_dems = [\"is_coder\", \"pref_pronouns\", \"year_born\", \"ethnicity_binary\", \n            \"dept_students_binary\", \"academia_status\"]\n\nviewof by_attr = Inputs.radio(col_dems, {label: \"attributes\"})\n\nplot_attr_v(filtered_dat, \"pref_pronouns\", by_attr, true, \"\", do_pct)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_attr_v(filtered_dat, \"academia_status\", by_attr, false, \"\", do_pct)\n\n\n\n\n\n\n\nplot_attr_v(filtered_dat, \"dept_students_lab\", by_attr, false, \"\", do_pct)\n\n\n\n\n\n\n\n\n\nYear born\n\nfunction plot_yr_born(dat, by_attr) {\n  const parseTime = d3.timeParse(\"%Y\");\n  const formatTime = d3.timeFormat(\"%Y\")\n  \n  return Plot.plot({\n    grid: true,\n    x: {\n      label: \"\", \n      tickRotate: 45,\n      tickFormat: d => formatTime(parseTime(d))\n      },\n    y: { \n      label: do_pct ? \" Frequency (%) ↑\" : \"# respondents ↑\", \n      percent: do_pct ? true : false\n      },\n    marks: [\n      Plot.rectY(\n        rm_nulls ? dat.filter(d => d[\"year_born\"] !== null) : dat,\n        Plot.binX({ y: do_pct ? \"proportion\" : \"count\" }, { \n          x: \"year_born\", r: 3, fill: d => by_attr ? d[by_attr] : \"grey\", \n          thresholds: 30, order: by_attr \n        })\n      ),\n      Plot.ruleY([0])\n    ]\n  })\n}\n\nplot_yr_born(filtered_dat, by_attr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDuration (sec)\n\nfunction plot_duration(dat, by_attr) {\n  return Plot.plot({\n    grid: true,\n    fy: {\n      label: \"\", \n    },\n    facet: { \n      data: rm_nulls ? dat.filter(d => d[\"duration_sec\"] !== null) : dat, \n      y: d => by_attr ? d[by_attr] : null,\n      marginRight: 130,\n      marginTop: 50,\n    },\n    x: { \n      transform: d => d / 60, \n      label: \"time(min)  →\",\n      domain: [0,d3.max(filtered_dat, d => (d[\"duration_sec\"] / 60) + 2)]\n    },\n    y: { \n      label: do_pct ? \" Frequency (%) ↑\" : \"# respondents ↑\", \n      percent: do_pct ? true : false\n    },\n    marks: [\n      Plot.rectY(\n        rm_nulls ? dat.filter(d => d[\"duration_sec\"] !== null && d[by_attr] !== null) : dat, \n        Plot.binX({ y: do_pct ? \"proportion\" : \"count\" }, {\n          x: \"duration_sec\", fill: d => by_attr ? d[by_attr] : \"grey\", thresholds: 20\n          })\n      ),\n      Plot.ruleY([0])\n    ]\n  })\n}\n\nplot_duration(filtered_dat, by_attr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOnly showing coders.\n\nviewof by_attr2 = Inputs.radio([\"gender_binary\", \"year_born\", \"ethnicity_binary\", \"dept_students_binary\", \"academia_status\"], {label: \"attributes\"})\n\nplot_attr_v(filtered_coders, \"self_id_as_coder\", by_attr2, true, \"Self id as coder\", do_pct)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_attr_v(filtered_coders, \"what_os\", by_attr2, false, \"What OS\", do_pct)\n\n\n\n\n\n\n\n\nFirst line code\n\nplot_attr_h(filtered_coders, \"first_line_code\", by_attr2, false, \"first line\")\n\n\n\n\n\n\nYears coding\n\nplot_attr_h(filtered_coders, \"years_coding\", by_attr2, false, \"years coding\")\n\n\n\n\n\n\n\n\n\nviewof form = Inputs.form({\n  extra_filter: Inputs.checkbox(['coder', 'female', 'stem', 'Non-stem'], {label: 'Only'}), \n  dep_var: Inputs.select(colnames, {value: 'self_id_as_coder', label: 'Dep var (DV)'}),\n  indep_var: Inputs.select(colnames, {value: 'gender_binary', label: 'Indep var (IV)'}), \n  do_pct_crosstab: Inputs.radio(['DV (→)', 'IV (↓)'], {label: \"Show %\", value: 'IV (↓)'})\n})\n\n\n\n\n\n\n\nfunction crosstab_filter(x) {\n    switch (x) {\n      case \"\":         return pdata; \n      case 'coder':    return pdata.filter(d => d.is_coder === 'coder'); \n      case 'female':   return pdata.filter(d => d.gender_binary === 'female'); \n      case 'stem':     return pdata.filter(d => d.dept_students_binary === 'STEM'); \n      case 'Non-stem': return pdata.filter(d => d.dept_students_binary === 'Non-STEM'); \n      case 'coder,female': \n        return pdata.filter(d => d.is_coder === 'coder' && d.gender_binary === 'female');\n      \n      case 'coder,stem': \n        return pdata.filter(d => d.is_coder === 'coder' && d.dept_students_binary === 'STEM');\n      \n      case 'female,stem': \n        return pdata.filter(d => d.gender_binary === 'female' && d.dept_students_binary === 'STEM');\n      \n      case 'female,Non-stem': \n        return pdata.filter(d => d.gender_binary === 'female' && d.dept_students_binary === 'Non-STEM');\n      \n      case 'coder,Non-stem': \n        return pdata.filter(d => d.is_coder === 'coder' && d.dept_students_binary === 'Non-STEM');\n      default:\n        return pdata.filter(d => d.is_coder === \"\")\n}}\n\ncrosstab_dat_filter1 = crosstab_filter(form.extra_filter.join(\",\"))\n\ncrosstab_dat_filter2 = {\n  if (rm_nulls) {\n      return crosstab_dat_filter1.filter(d => d[form.dep_var] !== null && d[form.indep_var] !== null) \n  } else {\n      return crosstab_dat_filter1\n  }\n}\n\ncrosstab_dat_long = tidy(\n    crosstab_dat_filter2, \n    select([form.indep_var, form.dep_var]),\n    count([form.indep_var, form.dep_var])\n)\n\ncols_ordered = [form.dep_var].concat(\n  tidy(crosstab_dat_long, distinct(form.indep_var), arrange(form.indep_var)\n  ).map(d => d[form.indep_var])\n)\n\ncrosstab_dat_w_pct = tidy(\n  crosstab_dat_long,\n  groupBy(form.do_pct_crosstab == 'DV (→)' ? form.dep_var : form.indep_var, [\n    mutateWithSummary({total: sum('n')})\n  ]),\n  mutate({ pct: d => (d.n / d.total)*100 }),\n  select(['-n', '-total'])\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThird variable: \nPercentage data\n\nInputs.table(tidy(\n    crosstab_dat_w_pct,\n    pivotWider({ namesFrom: form.indep_var, valuesFrom: 'pct' }),\n    arrange(form.dep_var)\n    ), { columns: cols_ordered })\n\n\n\n\n\n\nRaw data\n\nInputs.table(tidy(\n  crosstab_dat_long, \n  pivotWider({ namesFrom: form.indep_var, valuesFrom: 'n' }),\n  arrange(form.dep_var)\n  ), { columns: cols_ordered }\n)\n\n\n\n\n\n\n\nfunction notes_crosstab(x) {\n  switch (x) {\n        case \"self_id_as_coder ~ gender_binary\":         \n          return \"It seems that female less affirmatively  self-identify as coders, whereas male are less ambiguous about it. When adding `stem`, male respond more affirmatvely to the question, but note that we have still a small sample. Is this something that holds when controlling for experience?\"; \n        default:\n          return \"\"\n  }\n}\n\nnotes = notes_crosstab(`${form.dep_var} ~ ${form.indep_var}`)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes:\n\nThere are  respondents shown in the table.\nDoes this crosstable passes the rule of five? \n\n\n\n\nprofile_cols = ['academia_status', 'nb_advisors', 'dept_students_lab', \"pref_pronouns\", \n                \"year_born\", \"ethnicity_binary\", 'country_origin', 'us_state', 'reason_coding', 'how_did_you_learn_code','first_line_code', 'first_line_code_c','years_coding',  'freq_coding_proj', 'freq_coding_proj_c', 'freq_oss_proj', 'what_os', 'position_industry', 'use_lang']\n\nInputs.table(pdata, { columns: profile_cols })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n    Question \n    Label \n  \n \n\n  \n    What is your academic status? \n    academia_status \n  \n  \n    Do you agree to the above terms? \n    agree_term \n  \n  \n    Q_RecaptchaScore \n    captcha_score \n  \n  \n    When using other people's code, how do you cite their library/repository? \n    cite_code \n  \n  \n    When using other people's data, do you cite their library/repository? How? \n    cite_data \n  \n  \n    How likely you think that not knowing how to program will have an impact on future professional opportunities? \n    coding_on_future_opportunities \n  \n  \n    If you have any suggestions/comments about the survey, please share them below! \n    comments \n  \n  \n    Now, thinking about the expectations in your field: would you say that the expected level of programming skills in your field is an important factor in your choice to pursue an academic career? \n    comp_skills_factors_pursue_academia \n  \n  \n    How important do you think your programming skills were for your career? \n    comp_skills_pro_benefits_p \n  \n  \n    Do you think programming will bring you professional benefits in the future? \n    comp_skills_pro_benefits_s \n  \n  \n    How important do you think your programming skills are to prospective group members? \n    comp_skills_recruiting \n  \n  \n    How important programming skills are when hiring new group members? - Graduate students \n    comp_skills_recruiting_grad \n  \n  \n    How important programming skills are when hiring new group members? - Postdoctoral researchers \n    comp_skills_recruiting_postdoc \n  \n  \n    How important programming skills are when hiring new group members? - Undergraduate students \n    comp_skills_recruiting_undergrad \n  \n  \n    List of Countries \n    country_origin \n  \n  \n    What is your department? Please select all that apply. \n    dept_prof \n  \n  \n    What is your program? \n    dept_students \n  \n  \n    Do you feel disadvantaged for not knowing how to code? \n    disadv_not_coding \n  \n  \n    Distribution Channel \n    distribution_channel \n  \n  \n    If you wish to delete your survey entry write \"delete\" below \n    do_del \n  \n  \n    Do you share your code online? \n    do_share_code_online \n  \n  \n    Duration (in seconds) \n    duration_sec \n  \n  \n    What is your institutional email address? \n    email \n  \n  \n    End Date \n    end_survey \n  \n  \n    Do you think you have enough institutional support (workshops, mentorships, online labs) to learn to program? \n    enough_instit_support \n  \n  \n    Which categories best describe you? \n    ethnicity \n  \n  \n    At what age did you write your first line of code or program? (e.g., webpage, Hello World, Scratch project) \n    first_line_code \n  \n  \n    When you are working on projects (for school, work, fun)  how often  do you code? \n    freq_coding_proj \n  \n  \n    How much of the software that you use is open source? (please provide your best guess) \n    freq_oss_proj \n  \n  \n    Do you feel you have friends, colleagues, or supervisors who can help with your coding issues? \n    friends_help \n  \n  \n    How did you first learn to code? \n    how_did_you_learn_code \n  \n  \n    Finished \n    is_finished \n  \n  \n    Overall, would you like to have more time to improve your programming skills? \n    more_time_learning_to_code \n  \n  \n    What is the name of your research group? \n    name_research_group \n  \n  \n    How many advisors do you have? \n    nb_advisors \n  \n  \n    What percentage of your social contacts are likely to participate in a project that require programming in the upcoming academic year. Social contacts are classmates and other peers that you have communicated with at least briefly within the last month, either face-to-face, or otherwise. - Click to write Choice 1 \n    pct_social_contacts_coding \n  \n  \n    What benefits do you see in programming? \n    perceived_benefits_coding \n  \n  \n    Which of the following describes industry positions you have held or currently hold? \n    position_industry \n  \n  \n    What is your preferred pronouns? \n    pref_pronouns \n  \n  \n    Progress \n    progress \n  \n  \n    What qualities do you most value in software ? \n    qualities_oss \n  \n  \n    How often do you read programming books, either to improve your long-term coding skills or out of interest? \n    read_prog_book \n  \n  \n    Do you code for any of the following reasons? \n    reason_coding \n  \n  \n    Recorded Date \n    record_date \n  \n  \n    Response ID \n    response_id \n  \n  \n    Response Type \n    response_type \n  \n  \n    Score \n    score \n  \n  \n    For any of your current projects, do you consider that you spent too much time to code? (e.g. data cleaning, data visualization, gathering data, and so on)? \n    self_expect_time_coding \n  \n  \n    Do you consider yourself to be a coder/programmer? \n    self_id_as_coder \n  \n  \n    Start Date \n    start_survey \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Cleaning code (debugging, refactoring, renaming variables, etc.) \n    time_cleaning_code \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Data cleaning (manually, e.g. using excel) \n    time_data_clean_gui \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Data cleaning (programmatically) \n    time_data_clean_prog \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Digital data collection (e.g. web scraping) \n    time_digital_data_coll \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Experimental manipulation \n    time_exp_manip \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Field data collection (e.g. interviews, surveys, questionnaires, observations, ethnographies, etc) \n    time_field_data_coll \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Grant writing \n    time_grant_writing \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Literature review \n    time_lit_review \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Meetings \n    time_meeting \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Writing thesis/paper \n    time_paper_writing \n  \n  \n    Coursework aside, how many hours you typically spend on the following tasks in a given week? (please provide your best guess) - Reading software-related content (blogs, books, forums, documentation) \n    time_read_doc \n  \n  \n    Do you consider yourself a member of an underrepresented group? \n    underrep_group \n  \n  \n    50 States, D.C. and Puerto Rico \n    us_state \n  \n  \n    Which programming languages, scripting, and markup languages have you worked in over the past year? \n    use_lang \n  \n  \n    User Language \n    user_lang \n  \n  \n    How important do you think the following items are in academia? - Code associated with an article is easy to find online \n    value_accessibility_paper_code \n  \n  \n    When thinking about whether to use open source software, how important are the following: - Active development \n    value_active \n  \n  \n    When thinking about whether to use open source software, how important are the following: - A contributor's license agreement (CLA) \n    value_cla \n  \n  \n    When thinking about whether to use open source software, how important are the following: - A code of conduct \n    value_coc \n  \n  \n    Compared to your domain expertise, how valued do you think your coding skills are around you today? \n    value_comp_skills_wrt_domain \n  \n  \n    When thinking about whether to use open source software, how important are the following: - A contributing guide \n    value_contrib_guide \n  \n  \n    Overall, how important do you think it is to learn programming in your academic field today? \n    value_learn_code_in_field \n  \n  \n    When thinking about whether to use open source software, how important are the following: - An open source license \n    value_oss_license \n  \n  \n    How important do you think the following items are in academia? - Code associated with an article is citable. \n    value_paper_code_citability \n  \n  \n    When thinking about whether to use open source software, how important are the following: - Responsive maintainers \n    value_responsive_maintainers \n  \n  \n    How important do you think the following items are in academia? - Sharing code associated with an academic paper \n    value_share_code \n  \n  \n    When thinking about whether to use open source software, how important are the following: - A welcoming community \n    value_welcoming_community \n  \n  \n    When thinking about whether to use open source software, how important are the following: - Widespread use \n    value_widespread_use \n  \n  \n    What is the primary operating system in which you work? \n    what_os \n  \n  \n    If you want to learn to program, what's stopping you? \n    why_not_coding \n  \n  \n    In what year were you born? \n    year_born \n  \n  \n    How many years have you been coding? \n    years_coding"
  },
  {
    "objectID": "posts/survey-programming/index.html#costs-benefits",
    "href": "posts/survey-programming/index.html#costs-benefits",
    "title": "Survey results (early release)",
    "section": "Costs & benefits",
    "text": "Costs & benefits\n\nviewof sel_dept_cb = Inputs.select([''].concat(\n  tidy(\n    pdata.filter(d => d[\"dept_students_lab\"] !== null),\n    distinct('dept_students_lab')\n  ).map(d => d[\"dept_students_lab\"])), { label: \"Choose dept\" })\n\nviewof by_attr_cb = Inputs.radio([\"pref_pronouns\", \"year_born\", \"ethnicity_binary\", \"dept_students_binary\", \"academia_status\"], { label: \"attributes\" })\nviewof do_pct_2 =   Inputs.toggle({ label: \"Show %\" }) \nviewof show_labs =   Inputs.toggle({ label: \"Show Labels\" }) \nviewof rm_nulls_2 = Inputs.toggle({ label: \"Remove nulls\", value: true })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCostsBenefitsOSSData\n\n\nSmaller values are more negative attitude.\n\nplot_attr_v(coders, \n  show_labs ? \"enough_instit_support\" : \"enough_instit_support_ord\",      \n  by_attr_cb, true,  \n  show_labs ? \"\" : \"Institutional support\",\n  do_pct_2\n)\n\n\n\n\n\n\n\nplot_attr_v(coders,   \n  show_labs ? \"more_time_learning_to_code\": \"more_time_learning_to_code_ord\", \n  by_attr_cb, \n  false, \n  show_labs ? \"\" : \"More time learning to code\",   \n  do_pct_2\n)\n\n\n\n\n\n\n\nplot_attr_v(coders, \n show_labs ? \"self_expect_time_coding\" : \"self_expect_time_coding_ord\", \n    by_attr_cb, \n    false, \n    show_labs ? \"\" : \"Self expectation time coding\", \n    do_pct_2\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nDepending on other variables, the answers to these questions can be interepreted both as relative costs or benefits, e.g. thinking that expected level of programming skills is important in your field is a cost when you are not skilled yet.\n\n\n\n\nplot_attr_v(coders, show_labs ? \"value_comp_skills_wrt_domain\" : \"value_comp_skills_wrt_domain_ord\", by_attr_cb, false, show_labs ? \"\" : \"Value comp skills wrt domain\",  do_pct_2)\n\n\n\n\n\n\n\nfunction plot_social_contacts(dat, by_attr) {\n  return Plot.plot({\n    grid: true,\n    x: {\n      label: \"Social contact coding (%)  →\",\n    },\n    y: { \n      label: do_pct_2 ? \" Frequency (%) ↑\" : \"# respondents ↑\", \n      percent: do_pct_2 ? true : false\n    },\n    marks: [\n      Plot.barY(\n        rm_nulls ? dat.filter(d => d[\"pct_social_contacts_coding\"] !== null) : dat, \n        Plot.groupX({ y: do_pct_2 ? \"proportion\" : \"count\" }, { \n            x: \"pct_social_contacts_coding\",  fill: d => by_attr ? d[by_attr] : \"grey\"\n          })\n      ),\n      Plot.ruleY([0])\n    ]\n  })\n}\n\nplot_social_contacts(coders, by_attr_cb)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAttitude Open science & Open source\n\nplot_attr_v(coders, \"do_share_code_online\",           by_attr_cb, true,  \"\", do_pct_2)\n\n\n\n\n\n\n\nplot_attr_v(coders, \"value_paper_code_citability_ord\",    by_attr_cb, false, \"Code Citability\", do_pct_2)\n\n\n\n\n\n\n\nplot_attr_v(coders, \"value_accessibility_paper_code_ord\", by_attr_cb, false, \"Accessibility paper code\", do_pct_2)\n\n\n\n\n\n\n\nplot_attr_v(coders, \"value_share_code_ord\",               by_attr_cb, false, \"Code Sharing\", do_pct_2)\n\n\n\n\n\n\n\nplot_attr_v(coders, \"value_welcoming_community_ord\",  by_attr_cb, false, \"Welcoming community\", do_pct_2)\n\n\n\n\n\n\n\nplot_attr_v(coders, \"value_widespread_use_ord\",  by_attr_cb, false, \"Widespread use\", do_pct_2)\n\n\n\n\n\n\n\n\n\n\n\n\ncost_cols = ['pct_social_contacts_coding', 'comp_skills_factors_pursue_academia',\n             'comp_skills_pro_benefits_s', 'enough_instit_support',\n             'friends_help', 'perceived_benefits_coding', 'first_adv_expect_time_coding',\n             'second_adv_expect_time_coding', 'reason_coding',  'value_comp_skills_wrt_domain', \n             'do_share_code_online', \"value_learn_code_in_field\"]\n\nInputs.table(coders, { columns: cost_cols })"
  },
  {
    "objectID": "posts/survey-programming/index.html#students-typical-week",
    "href": "posts/survey-programming/index.html#students-typical-week",
    "title": "Survey results (early release)",
    "section": "Students typical week",
    "text": "Students typical week\n\n\nagg_dat = tidy(\n  coders, \n  select([startsWith('time')]), \n  pivotLonger({\n    cols: [startsWith('time')],\n    namesTo: 'task',\n    valuesTo: 'val'\n  }),\n  count(['task', 'val']\n))\n\n\nPlot.plot({\n  width: 1000,\n  marginBottom: 100,\n  grid: true,\n  x: {\n    tickRotate: 45,\n    label: \"\",\n    domain: ['0 hour', '1-5 hours', '6-10 hours', '11-15 hours', null]\n  },\n  facet: {\n    data: agg_dat,\n    x: d => d.task.replace('time_', '')\n  },\n  marks: [\n    Plot.barY(\n      agg_dat,\n      {x: \"val\", y: \"n\", fill: d => d.val === null ? 'grey' : 'task'}\n    ),\n    Plot.ruleY([0])\n  ]\n})"
  },
  {
    "objectID": "posts/survey-programming/index.html#what-do-non-coders-think-about-coding",
    "href": "posts/survey-programming/index.html#what-do-non-coders-think-about-coding",
    "title": "Survey results (early release)",
    "section": "What do non-coders think about coding?",
    "text": "What do non-coders think about coding?\n\nviewof do_pct_nc =   Inputs.toggle({ label: \"Show %\" }) \nviewof show_labs_nc =   Inputs.toggle({ label: \"Show Labels\" })\nviewof by_attr_nc = Inputs.radio([\"pref_pronouns\", \"year_born\", \"ethnicity_binary\", \"dept_students_binary\", \"academia_status\"], { label: \"attributes\" })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnon_coders.map(d => d.value_learn_code_in_field_ord)\n\n\n\n\n\n\n\n\nPlot.plot({\n      marginLeft: 175,\n      grid: true,\n      // y: { \n        // domain: d3.sort(non_coders, d => d[\"value_learn_code_in_field_ord\"]).map(d => d[\"value_learn_code_in_field\"])\n        // },\n      x: { \n        label: \" Frequency (%) →\", \n      },\n      marks: [\n      Plot.barX(\n          non_coders.filter(d => d[\"value_learn_code_in_field_ord\"] !== null && d[\"value_learn_code_in_field_ord\"] !== \"NA\"),\n          Plot.groupY({ x: \"count\" }, { \n              y: \"value_learn_code_in_field_ord\" })\n        ),\n      ]\n  })\n\n\n\n\n\n\n\nplot_attr_v(non_coders, \nshow_labs_nc ? \"value_learn_code_in_field\" : \"value_learn_code_in_field_ord\",    by_attr_nc, true, show_labs_nc ? \"\" : \"Coding on future opportunities\", do_pct_nc)\n\n\n\n\n\n\n\nimport { tidy, select, count, complete, filter, fullSeq, sum, mutateWithSummary, groupBy, pivotWider, startsWith, pivotLonger, mutate, distinct, summarize, arrange, pull } from '@pbeshai/tidyjs'"
  },
  {
    "objectID": "posts/source-sink/index.html",
    "href": "posts/source-sink/index.html",
    "title": "Source-sink behavioural dynamics limit institutional evolution in a group structured society",
    "section": "",
    "text": "Model Sketch\n\n\n\n\n\n\n\n\n\nThe key ingredients of the model are our groups \\(G\\) with the number of adopters \\(i\\) and with an institution of level \\(\\ell\\). We assume that with higher levels of institutional strength, \\(\\ell\\), the institution will more effectively promote group-beneficial behavior, \\(\\ell\\)\\(\\beta\\). As it gets better, each adopter in the group also gain a collective benefit \\(b\\). But all of these toodily-doo perks are offset by an institutional implementation costs, \\(c\\), of entertaining larger groups. For instance, think of the process of unionization, promoting behaviors that are costly at individual level. When unionization becomes more successful, the unions can become ungaingly. Lastly adopters lose their behavioural trait at a rate \\(\\gamma\\).\nFirst master equation1:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{diff} &= \\ell \\mathbin{\\color{darkgreen}{\\beta}} [(i-1) + R](n - i + 1)G_{i-1,\\ell} \\\\\n                              &- \\ell\\mathbin{\\color{darkgreen}{\\beta}} (i+R)(n-i) G_{i,\\ell} \\\\\n                              &+ \\mathbin{\\color{red}{\\gamma}}(i+1)G_{i+1,\\ell} - \\mathbin{\\color{red}{\\gamma}} i G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(R = \\mathbin{\\color{blue}{\\rho}} \\sum_{i',\\ell'} i'G_{i',\\ell'}\\) represents the global diffusion of behaviors and primes denote variable over which we sum to calculate global quantity. The sum over adopters at each level weighted by global behavioural diffusion \\(\\rho\\).\nSecond master equation:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{select} &= \\mathbin{\\color{blue}{\\rho}} [G_{i,\\ell-1}(Z_\\ell Z_{\\ell-1}^{-1} + \\mathbin{\\color{midnightblue}{\\mu}}) + G_{i,\\ell+1}(Z\\ell Z_{\\ell + 1}^{-1} + \\mathbin{\\color{midnightblue}{\\mu}})] \\\\\n                                &-\\mathbin{\\color{blue}{\\rho}}(Z_{\\ell-1}Z_\\ell^{-1} + Z_{\\ell+1}^{-1} + 2\\mathbin{\\color{midnightblue}{\\mu}})G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(Z_\\ell = \\frac{\\sum_{i'} exp(\\mathbin{\\color{seagreen}{b}}i'- \\mathbin{\\color{darkred}{c}}\\ell)G_{i',\\ell}}{\\sum_{i'}G_{i',\\ell}}\\). Note that we add a constant rate of transition \\(\\mu\\) to the selection proces.\nTaken togetherm we have the set of master equations:\n\\[\n\\frac{d}{dt}G_{i,\\ell} = \\frac{d}{dt}G_{i,\\ell}^{diff} + \\frac{d}{dt}G_{i,\\ell}^{select}\n\\]"
  },
  {
    "objectID": "posts/source-sink/index.html#julia-model",
    "href": "posts/source-sink/index.html#julia-model",
    "title": "Source-sink behavioural dynamics limit institutional evolution in a group structured society",
    "section": "Julia model",
    "text": "Julia model\n\n\n\n\n\n\nInitialization scheme\n\n\n\n\n\nfunction initialize_u0(;n::Int=20, L::Int=6, M::Int=20, p::Float64=0.01)\n  G = zeros(L, n+1)\n\n  for _ in 1:M\n    ℓ = rand(1:L) # pick a level\n    i = sum(collect(rand(Binomial(1, p), n))[1]) # how many total adopters?\n    G[ℓ, i+1] += 1 # everytime combination G[ℓ,i], count +1\n  end\n\n  G = G ./ M # normalized by tot number of groups\n\n  # ArrayPartition are nice because we can access the level such as G.x[ℓ][i]\n  return ArrayPartition(Tuple([G[ℓ,:] for ℓ=1:L]))\nend\n\nn, M = 20, 1000\nu₀ = initialize_u0(n=n, L=6, M=M, p=0.01)\np = [β, γ, ρ, b, c, μ]\ntspan = (1.0, 4000)\nprob = ODEProblem(source_sink!, u₀, tspan, p)\nsol = solve(prob, DP5(), saveat = 1., reltol=1e-8, abstol=1e-8)\n\n\n\nfunction source_sink!(du, u, p, t)\n    G, L, n = u, length(u.x), length(first(u.x))\n    β, γ, ρ, b, c, μ = p\n    Z, pop, R = zeros(L), zeros(L), 0.\n\n    # Calculate mean-field coupling and observed fitness landscape\n    for ℓ in 1:L\n      n_adopt = collect(0:(n-1))\n      Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ])\n      pop[ℓ]  = sum(G.x[ℓ])\n      R       += sum(ρ*n_adopt .* G.x[ℓ])\n      pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] )\n    end\n\n    for ℓ = 1:L, i = 1:n\n      n_adopt, gr_size = i-1, n-1\n\n      # Diffusion events\n      du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - (ℓ-1)*β*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]\n\n      n_adopt > 0 && ( du.x[ℓ][i] += β*(ℓ-1)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])\n      n_adopt < gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )\n\n      # Group selection process\n      ℓ > 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )\n      ℓ < L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )\n    end\nend"
  },
  {
    "objectID": "posts/source-sink/index.html#output",
    "href": "posts/source-sink/index.html#output",
    "title": "Source-sink behavioural dynamics limit institutional evolution in a group structured society",
    "section": "Output",
    "text": "Output\n\n\n\n\ndata = FileAttachment(\"data.json\").json()\np = Object.keys(data).map(d => d.split(\"_\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nminmax = (p, i) => d3.extent(p.map(d => parseFloat(d[i])))\n\nviewof beta  = Inputs.range(minmax(p,0), {step: 0.05, label: \"β\", value:\"0.07\"})\nviewof gamma = Inputs.range(minmax(p,1), {step: 0.1,  label: \"γ\", value:\"1.0\"})\nviewof rho   = Inputs.range(minmax(p,2), {step: 0.15, label: \"ρ\", value:\"0.1\"})\nviewof b     = Inputs.range(minmax(p,3), {step: 0.05, label: \"b\", value:\"0.18\"})\nviewof c     = Inputs.range(minmax(p,4), {step: 0.5,  label: \"c\", value:\"1.05\"})\nviewof mu    = Inputs.range(minmax(p,5), {step: 0.03, label: \"μ\", value:\"0.0001\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\n\n\n\nf = (x) => Number.isInteger(x) ? x.toPrecision(2) : x\n\nPlot.plot({\n  x: {type:\"log\"},\n  y: {domain: [0,1]},\n  color: {scheme: \"reds\", type: \"ordinal\", legend: true},\n  marks: [\n    Plot.line(\n      data[`${f(beta)}_${f(gamma)}_${f(rho)}_${f(b)}_${f(c)}_${f(mu)}`], {\n        x: 'timesteps', y: \"value\", stroke: \"L\"\n        }),\n    Plot.dot(\n      data[`${f(beta)}_${f(gamma)}_${f(rho)}_${f(b)}_${f(c)}_${f(mu)}`], {\n        x: 'timesteps', y: \"value\", stroke: \"L\"\n        })\n  ]\n})"
  },
  {
    "objectID": "posts/source-sink/index.html#takeaways",
    "href": "posts/source-sink/index.html#takeaways",
    "title": "Source-sink behavioural dynamics limit institutional evolution in a group structured society",
    "section": "Takeaways:",
    "text": "Takeaways:\n\nFrequency of behaviour in groups with different institutional strength.\nWithin groups, the frequency of cooperative behaviour follows the strength of institutions (with ℓ = 1 in light beige and ℓ = 6 in dark red).\nQualitatively, no institutions are possible if institutional costs are too high, and the behaviour never spreads.\nThe time dynamics of global behavioural frequency and behaviour in groups can include patterns of surge and collapse."
  },
  {
    "objectID": "posts/modeling-survey-prog/index.html",
    "href": "posts/modeling-survey-prog/index.html",
    "title": "Survey modeling (early release)",
    "section": "",
    "text": "Logistic regression\n\nWheiss’ writeup on Bayes Rules! Ch. 13\n\n\nModel 1: E ~ RSNModel 2: RSN ~ D + GData\n\n\n\n\nCode\ncoder_log_reg <- coder %>% \n  select(pct_social_contacts_coding, first_line_code_before_18) |> \n  mutate(across(c(pct_social_contacts_coding), \n                ~scale(., scale = FALSE), .names = \"{col}_centered\")) |> \n  mutate(across(c(pct_social_contacts_coding), \n                ~as.numeric(scale(., scale = FALSE)), .names = \"{col}_c\"))\n\nextract_attributes <- function(x) {\n  attributes(x) %>%\n    set_names(janitor::make_clean_names(names(.))) %>%\n    as_tibble() %>%\n    slice(1)\n}\n\nunscaled <- coder_log_reg %>%\n  select(ends_with(\"_centered\")) |> \n  summarize(across(everything(), ~extract_attributes(.))) |> \n  pivot_longer(everything()) |> \n  unnest(value) |> \n  split(~name)\n\n\n\n\n\n\n\n\nAlgebraic model\n\n\n\n\n\n\\[\\begin{align*}\n  \\text{RSN}_i &\\sim \\text{Bernoulli}(\\pi_i) \\\\\n  \\text{logit}(\\pi_i) &= \\beta_0 D_i + \\beta_1 G_i\n\\end{align*}\\]\n\n\n\n\n\nCode\npriors <- c(prior(normal(-1.39, 0.7), class = Intercept),\n            prior(normal(0.07, 0.035), class = b, coef = \"pct_social_contacts_coding_c\"))\n\nmodel_weather_prior_brms <- brm(\n  bf(first_line_code_before_18 ~ pct_social_contacts_coding_c),\n  data = coder,\n  family = bernoulli(link = \"logit\"),\n  prior = priors,\n  sample_prior = \"only\",\n  chains = 4, iter = 4000, seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0\n)\n\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nIn file included from stan/lib/stan_math/lib/boost_1.75.0/boost/multi_array/multi_array_ref.hpp:32,\n                 from stan/lib/stan_math/lib/boost_1.75.0/boost/multi_array.hpp:34,\n                 from stan/lib/stan_math/lib/boost_1.75.0/boost/numeric/odeint/algebra/multi_array_algebra.hpp:22,\n                 from stan/lib/stan_math/lib/boost_1.75.0/boost/numeric/odeint.hpp:63,\n                 from stan/lib/stan_math/stan/math/prim/functor/ode_rk45.hpp:9,\n                 from stan/lib/stan_math/stan/math/prim/functor/integrate_ode_rk45.hpp:6,\n                 from stan/lib/stan_math/stan/math/prim/functor.hpp:14,\n                 from stan/lib/stan_math/stan/math/rev/fun.hpp:193,\n                 from stan/lib/stan_math/stan/math/rev.hpp:10,\n                 from stan/lib/stan_math/stan/math.hpp:19,\n                 from stan/src/stan/model/model_header.hpp:4,\n                 from /tmp/Rtmp9zjsFC/model-403bf4d1b439c.hpp:3:\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:180:45: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]\n  180 |         : public boost::functional::detail::unary_function<typename unary_traits<Predicate>::argument_type,bool>\n      |                                             ^~~~~~~~~~~~~~\nIn file included from /usr/include/c++/12/string:48,\n                 from /usr/include/c++/12/bits/locale_classes.h:40,\n                 from /usr/include/c++/12/bits/ios_base.h:41,\n                 from /usr/include/c++/12/ios:42,\n                 from /usr/include/c++/12/istream:38,\n                 from /usr/include/c++/12/sstream:38,\n                 from /usr/include/c++/12/complex:45,\n                 from stan/lib/stan_math/lib/eigen_3.3.9/Eigen/Core:96,\n                 from stan/lib/stan_math/lib/eigen_3.3.9/Eigen/Dense:1,\n                 from stan/lib/stan_math/stan/math/prim/fun/Eigen.hpp:22,\n                 from stan/lib/stan_math/stan/math/rev.hpp:4:\n/usr/includ\n\n\ne/c++/12/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\n\n\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:214:45: warning: ‘template<class _Arg1, class _Arg2, class _Result> struct std::binary_function’ is deprecated [-Wdeprecated-declarations]\n  214 |         : public boost::functional::detail::binary_function<\n      |                                             ^~~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:252:45: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]\n  252 |         : public boost::functional::detail::unary_function<\n      |                                             ^~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:299:45: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]\n  299 |         : public boost::functional::detail::unary_function<\n      |                                             ^~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:345:57: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]\n  345 |     class mem_fun_t : public boost::functional::detail::unary_function<T*, S>\n      |                                                         ^~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:361:58: warning: ‘template<class _Arg1, class _Arg2, class _Result> struct std::binary\n\n\n_function’ is deprecated [-Wdeprecated-declarations]\n  361 |     class mem_fun1_t : public boost::functional::detail::binary_function<T*, A, S>\n      |                                                          ^~~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:377:63: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]\n  377 |     class const_mem_fun_t : public boost::functional::detail::unary_function<const T*, S>\n      |                                                               ^~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:393:64: warning: ‘template<class _Arg1, class _Arg2, class _Result> struct std::binary_function’ is deprecated [-Wdeprecated-declarations]\n  393 |     class const_mem_fun1_t : public boost::functional::detail::binary_function<const T*, A, S>\n      |                                                                ^~~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:438:61: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]\n  438 |     class mem_fun_ref_t : public boost::functional::detail::unary_function<T&, S>\n      |                                                             ^~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:454:62: warning: ‘template<class _Arg1, class _Arg2, class _Result\n\n\n> struct std::binary_function’ is deprecated [-Wdeprecated-declarations]\n  454 |     class mem_fun1_ref_t : public boost::functional::detail::binary_function<T&, A, S>\n      |                                                              ^~~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\n\n\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:470:67: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]\n  470 |     class const_mem_fun_ref_t : public boost::functional::detail::unary_function<const T&, S>\n      |                                                                   ^~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:487:68: warning: ‘template<class _Arg1, class _Arg2, class _Result> struct std::binary_function’ is deprecated [-Wdeprecated-declarations]\n  487 |     class const_mem_fun1_ref_t : public boost::functional::detail::binary_function<const T&, A, S>\n      |                                                                    ^~~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:533:73: warning: ‘template<class _Arg, class _Result> struct std::unary_function’ is deprecated [-Wdeprecated-declarations]\n  533 |     class pointer_to_unary_function : public boost::functional::detail::unary_function<Arg,Result>\n      |                                                                         ^~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.75.0/boost/functional.hpp:557:74: warning: ‘template<class _Arg1, class _Arg2, class _Result> struct std::binary_function’ is deprecated [-Wdeprecated-declarations]\n  557 |     class pointer_to_binary_function : public boost::functional::detail::binary_function<Arg1,Arg2,Result>\n      |                                                                          ^~~~~~~~~~~~~~~\n/usr/include/c++/12/bits/stl_func\n\n\ntion.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\n\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.7 seconds.\n\n\nCode\np1 <- tibble(\n  pct_social_contacts_coding = seq(0, 100, by = 0.1)\n) |> \n  mutate(pct_social_contacts_coding_c = pct_social_contacts_coding - unscaled$pct_social_contacts_coding_centered$scaled_center) |> \n  add_epred_draws(model_weather_prior_brms, ndraws = 100) |> \n  ggplot(aes(x = pct_social_contacts_coding, y = .epred)) +\n  geom_line(aes(group = .draw), alpha = 0.5, size = 0.5, color = clrs[6]) +\n  labs(x = \"% Social Contacts Coding\", y = \"Probability first line of code before 18\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nCode\np2 <- tibble(\n  pct_social_contacts_coding = seq(0, 100, by = 0.1)\n) |> \n  mutate(pct_social_contacts_coding_c = pct_social_contacts_coding - unscaled$pct_social_contacts_coding_centered$scaled_center) |>\n  add_predicted_draws(model_weather_prior_brms, ndraws = 100) |> \n  group_by(.draw) |> \n  summarize(proportion_early_exp = mean(.prediction == 1)) |> \n  ggplot(aes(x = proportion_early_exp)) +\n  geom_histogram(binwidth = 0.02, color = \"white\", fill = clrs[1]) +\n  labs(x = \"Proportion of early experience in each draw\", y = \"Count\")\n\np1 | p2\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgebraic model\n\n\n\n\n\n\\[\\begin{align*}\n  \\text{RSN}_i &\\sim \\text{Bernoulli}(\\pi_i) \\\\\n  \\text{logit}(\\pi_i) &= \\beta_0 D_i + \\beta_1 G_i\n\\end{align*}\\]\n\n\n\n\n\nCode\n# priors <- c(prior(normal(-1.39, 0.7), class = Intercept),\n#             prior(normal(0.07, 0.035), class = b, coef = \"humidity9am_c\"))\n\n# model_weather_prior_brms <- brm(\n#   bf(raintomorrow ~ humidity9am_c),\n#   data = weather,\n#   family = bernoulli(link = \"logit\"),\n#   prior = priors,\n#   sample_prior = \"only\",\n#   chains = 4, iter = 4000, seed = BAYES_SEED, \n#   backend = \"cmdstanr\", refresh = 0\n# )\n\n\n\n\n\nAPA table\n\n\nCode\ndf |> count(pct_social_contacts_coding, first_line_code_before_18)\n\n\n# A tibble: 18 × 3\n   pct_social_contacts_coding first_line_code_before_18     n\n                        <dbl>                     <dbl> <int>\n 1                          0                         1     1\n 2                         10                         0     4\n 3                         10                         1     1\n 4                         20                         0     1\n 5                         30                         0     2\n 6                         40                         0     1\n 7                         40                         1     1\n 8                         50                         0     3\n 9                         60                         1     2\n10                         70                         0     3\n11                         70                         1     2\n12                         80                         0     1\n13                         90                         0     2\n14                         90                         1     1\n15                        100                         0     6\n16                         NA                         0     3\n17                         NA                         1     5\n18                         NA                        NA     8\n\n\nCode\nmake_apa_table(\n  coder |> \n    mutate(first_line_code_before_18 = ifelse(first_line_code_before_18 == 1, \"has early exp\", \"no early exp\")), \n    \"first_line_code_before_18\", \n    \"pct_social_contacts_coding\"\n  )\n\n\nWarning: Use of .data in tidyselect expressions was deprecated in tidyselect 1.2.0.\nℹ Please use `all_of(var)` (or `any_of(var)`) instead of `.data[[var]]`\n\n\n\n\n\n\n  \n  \n    \n      \n      has early exp\n      no early exp\n      Total\n      %\n    \n  \n  \n    \n      Pct Social Contacts Coding\n    \n    0\n1\n0\n1\n3.2\n    10\n1\n4\n5\n16.1\n    20\n0\n1\n1\n3.2\n    30\n0\n2\n2\n6.5\n    40\n1\n1\n2\n6.5\n    50\n0\n3\n3\n9.7\n    60\n2\n0\n2\n6.5\n    70\n2\n3\n5\n16.1\n    80\n0\n1\n1\n3.2\n    90\n1\n2\n3\n9.7\n    100\n0\n6\n6\n19.4\n  \n  \n  \n\n\n\n\n\n\nPlotting probs\n\n\nCode\n# logit_df <- tibble(humidity9am = seq(0, 100, length.out = 101),\n#                    logits = seq(-4, 6, length.out = 101)) |> \n#   mutate(odds = exp(logits)) |> \n#   mutate(probs = plogis(logits))\n\n\n\n\n\n\n\n\n(Ordered) logistic regression\n\nWheiss’ writeup on Statistical Rethinking Week 6\n\n\nModel 1: S ~ G + EModel 2: S ~ E + G:EData\n\n\n\n\n\n\n\n\nAlgebraic model\n\n\n\n\n\n\\[\\begin{align*}\n  y_i &\\sim \\text{Ordered Logit}(\\phi_i, \\alpha) \\\\\n  \\phi_i &= \\beta_1 G_i + \\beta_2 E_i \\\\\n  B_{1,2} &\\sim  \\mathcal{N}(0,0.5) \\\\\n  \\alpha_k &\\sim \\mathcal{N}(0,1) \\\\\n\\end{align*}\\]\n\n\n\n\n\nCode\npriors <- c(prior(normal(0, 1.5), class = Intercept))\ninits <- list(Intercepts = c(-1, 0, 1.2))\n\nmodel_ge <- brm(\n  bf(self_id_as_coder ~ is_male + first_line_code_before_18),\n  data = coder,\n  family = cumulative(link = \"logit\"),\n  prior = priors,\n  init = rep(list(inits), 4),\n  save_warmup = TRUE,\n  chains = 4, iter = 2000, seed = BAYES_SEED, cores = 4,\n  backend = \"cmdstanr\", refresh = 0,\n  file = \".cache/model-eg\"\n)\n\nmodel_ge\n\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: self_id_as_coder ~ is_male + first_line_code_before_18 \n   Data: coder (Number of observations: 37) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept[1]                 -0.28      0.54    -1.32     0.79 1.00     4124\nIntercept[2]                  1.30      0.57     0.19     2.45 1.00     4052\nis_male                       1.79      0.70     0.49     3.20 1.00     3340\nfirst_line_code_before_18     0.50      0.69    -0.85     1.88 1.00     3583\n                          Tail_ESS\nIntercept[1]                  2653\nIntercept[2]                  3202\nis_male                       2840\nfirst_line_code_before_18     2633\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\nsimulated_conditions <- tribble(\n  ~title, ~newdata,\n  \"Is_Male = 0, E = 0\", tibble(is_male = 0, first_line_code_before_18 = 0),\n  \"Is_Male = 1, E = 0\", tibble(is_male = 1, first_line_code_before_18 = 0),\n  \"Is_Male = 0, E = 1\", tibble(is_male = 0, first_line_code_before_18 = 1),\n  \"Is_Male = 1, E = 1\", tibble(is_male = 1, first_line_code_before_18 = 1),\n) |> \n  mutate(pred_plot = map2(newdata, title, ~{\n    model_ge |> \n      add_predicted_draws(newdata = .x) |> \n      ungroup() |> \n      count(.prediction) |> \n      mutate(prop = n / sum(n),\n             prop_nice = label_percent(accuracy = 0.1)(prop)) |> \n      ggplot(aes(x = .prediction, y = n)) +\n      geom_col(aes(fill = .prediction)) +\n      geom_text(aes(y = 50, label = prop_nice), color = \"white\", size = 2.5, \n                angle = 90, hjust = 0) +\n      scale_y_continuous(labels = scales::label_comma()) +\n      scale_fill_viridis_d(option = \"rocket\", end = 0.85, guide = \"none\") +\n      labs(x = \"Response\", y = \"Count\", title = .y) +\n      theme(plot.title = element_text(size = rel(1), hjust = 0.5))\n  }))\n\nwrap_plots(simulated_conditions$pred_plot, nrow = 2, byrow = FALSE)\n\n\n\n\n\n\nMASS::polr\n\n\nCode\n# 3 levels ~ 1/0 + 1/0\n# same in rstanarm\nlogistic1 <- MASS::polr(self_id_as_coder ~ is_male + first_line_code_before_18, \n                        data = coder, Hess = TRUE)\nsummary(logistic1)\n\n\nCall:\nMASS::polr(formula = self_id_as_coder ~ is_male + first_line_code_before_18, \n    data = coder, Hess = TRUE)\n\nCoefficients:\n                           Value Std. Error t value\nis_male                   1.6680     0.6759  2.4679\nfirst_line_code_before_18 0.4676     0.6620  0.7063\n\nIntercepts:\n          Value   Std. Error t value\nNo|Maybe  -0.3386  0.5175    -0.6543\nMaybe|Yes  1.1808  0.5573     2.1188\n\nResidual Deviance: 71.40308 \nAIC: 79.40308 \n(2 observations deleted due to missingness)\n\n\n\n\n\n\n\nCode\nmodel_e_gender <- brm(\n  bf(self_id_as_coder ~  first_line_code_before_18 + first_line_code_before_18:is_male),\n  data = coder,\n  family = cumulative(link = \"logit\"),\n  prior = priors,\n  init = rep(list(inits), 4),\n  save_warmup = TRUE,\n  chains = 4, iter = 2000, seed = BAYES_SEED, cores = 4,\n  backend = \"cmdstanr\", refresh = 0,\n  file = \".cache/model-e-gender\"\n)\n\nmodel_e_gender\n\n\n Family: cumulative \n  Links: mu = logit; disc = identity \nFormula: self_id_as_coder ~ first_line_code_before_18 + first_line_code_before_18:is_male \n   Data: coder (Number of observations: 37) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                                  Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept[1]                         -1.00      0.45    -1.91    -0.16 1.00\nIntercept[2]                          0.44      0.41    -0.36     1.24 1.00\nfirst_line_code_before_18            -0.32      0.79    -1.87     1.24 1.00\nfirst_line_code_before_18:is_male     1.91      1.11    -0.13     4.23 1.00\n                                  Bulk_ESS Tail_ESS\nIntercept[1]                          2958     2806\nIntercept[2]                          4849     3654\nfirst_line_code_before_18             2862     3025\nfirst_line_code_before_18:is_male     2557     2173\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\nmodel_e_gender |> \n  spread_draws(`^b_.*`, regex = TRUE) |> \n  mutate(`b_first_line_code_before_18:is_male` = b_first_line_code_before_18 + `b_first_line_code_before_18:is_male`) |> \n  pivot_longer(starts_with(\"b_\"), names_to = \".variable\") |> \n  group_by(.variable) |> \n  summarize(avg = mean(value))\n\n\n# A tibble: 4 × 2\n  .variable                              avg\n  <chr>                                <dbl>\n1 b_first_line_code_before_18         -0.324\n2 b_first_line_code_before_18:is_male  1.59 \n3 b_Intercept[1]                      -0.996\n4 b_Intercept[2]                       0.445\n\n\n\n\n\nAPA table: S ~ G + E\n\n\n\n\n\n\n  \n  \n    \n      \n      female\n      male\n      Total\n      %\n    \n  \n  \n    \n      Self Id As Coder\n    \n    No\n6\n3\n9\n24.3\n    Maybe\n8\n3\n11\n29.7\n    Yes\n4\n13\n17\n45.9\n    \n      First Line Code Before 18\n    \n    0\n12\n12\n24\n64.9\n    1\n6\n7\n13\n35.1\n  \n  \n  \n\n\n\n\n\n\nPlotting Ordinal Response"
  },
  {
    "objectID": "posts/interactive-stats/index.html",
    "href": "posts/interactive-stats/index.html",
    "title": "CDAE stats",
    "section": "",
    "text": "The equation:\n\\[n^* = \\frac{n_0}{1 + \\frac{n_0}{N}}\\]\nwhere \\(n_0 = z_\\alpha^2 \\frac{S^2}{D^2}\\), \\(S^2\\) is our population variance, \\(D^2\\) is the difference between the true value and the estimated value, and \\(z_\\alpha^2\\) is the \\(z\\) value at a given confidence interval.1\n\n\n\nWe know…\n\nThere are 5,000 nonprofits in the city of reference\nFrom a previous study, we know that the the mean value of using new tools is $3,000. We also know from previous studies that the s.d. of this is $3,500.\n\nWe want…\n\nAn error rate of 10%\nA confidence interval of 95%\n\n\n\nfunction calc_n_0(z_alpha_sq, S, D) {\n    return z_alpha_sq * (S**2 / D**2)\n}\n\nfunction effective_sample_size(z_alpha_sq, S, D, N) {\n    const n_0 = calc_n_0(z_alpha_sq, S, D)\n    return +(n_0 / (1 + (n_0 / N))).toFixed(1)\n}\n\nfunction ci2z(ci) {\n     if (ci === \".68\") {\n        return 1\n     } else if (ci === \".95\") {\n        return 2\n     } else if (ci === \".99\") {\n        return 3\n     }\n}\n\nviewof conf_int = Inputs.radio([\".68\", \".95\", \".99\"], {value: \".95\", label: \"Conf. interval\"})\nviewof error_rate = Inputs.range([0.05, 1], {value: 0.1, step: 0.05, label: \"Error rate\"})\nviewof N = Inputs.range([0, 100000], {value: 5000, step: 1000, label: \"N\"})\nviewof prev_mean = Inputs.range([0, 10000], {value: 3000, step: 500, label: \"Prev mean\"})\nviewof prev_std = Inputs.range([0, 10000], {value: 3500, step: 500, label: \"Prev std\"})\nz_alpha_sq = ci2z(conf_int)**2\n\nS = prev_std\nD = error_rate * prev_mean\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, \\(S^2\\) is the previous standard deviation squared and \\(D\\) is the wanted error rate times the previous mean, that is,  x  = .\nWe find that the minimum adequate sample size, or \\(n^*\\):\n\\(n^0\\) = \n\\(n^*\\) =  / (1 +  / ) = \n\\(n_0/N\\) = \nAlso, we saw in class that \\(n^*\\) converges around \\(600\\), with the default parameters. That is, adding more data does not entail a higher \\(n^*\\). You can observe that fact with the following plot:\n\nxs = [...Array(N).keys()];\nys = xs.map(x => effective_sample_size(z_alpha_sq, S, D, x))\nPlot.lineY(ys).plot({height: 200, width: 300, y: {label: \"↑ n*\"}, x: {label: \"N →\"}})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBut you can play around with other settings to see how it varies."
  },
  {
    "objectID": "posts/interactive-stats/index.html#power-analysis",
    "href": "posts/interactive-stats/index.html#power-analysis",
    "title": "CDAE stats",
    "section": "Power analysis",
    "text": "Power analysis\nSee Patrick Mineault notebook"
  },
  {
    "objectID": "posts/interactive-stats/index.html#the-many-lives-of-statistical-tests",
    "href": "posts/interactive-stats/index.html#the-many-lives-of-statistical-tests",
    "title": "CDAE stats",
    "section": "The many lives of statistical tests",
    "text": "The many lives of statistical tests\nSometimes I feel that the popularity of statistical testing is about outsourcing statistical work of busy scientists to flow charts. In research methods courses focusing on statistical testing I feel there is an understanding that these are limited, but given time and interest of students, it’s better than nothing. And if you’re sticking to experimental setups, that might be all you need. I am not going to do a rant. But I want to supplement the usual search method class with alternative perspectives explained as simply as possible:\n\nThe Frequentist approach. This if often the first encounter with inferential statistics in social socience. As long as you are in an experimental set-up this might be fine. You need to think about probability as long-run probability.\nThe linear models approach. Instead of starting from statistical tests, we start from linear models and explain which models map onto which tests. This approach promotes flexibility at the costs of having to learn the underlying ideas of linear models.\nHypothesis testing but Bayesian. No need to remember the nonsense that we “fail to reject the null” and that 0.95 confidence interval does not mean that we are “95% confident that our results are significant”.\nThe Bootstrap approach. This is a great coding exercice and saves you time from remembering all the different tests.\n\nNote that we use the following emojis to encode data types:\n\n💡 : Yes/no, 2 levels, success/failure, bias/fair… nominal data.\n📊 : Yes/no/maybe, >2 levels, might be ordinal or nominal.\n📏 : continuous/scalar/uncountable data.\n\n\n💡 ~ 💡📊 ~ 💡📏 ~ 💡\n\n\n\n\n\n\nNHST\n\n\nR code\na <- chisq.test(d_mat) # p-value > 0.05\n\n\n\n\nLinear models\n\n\nR code\n# Using glm to do a log-linear model\nfull = glm(n ~ early_first_line * sex, family = poisson(), data = d_long) \nb = anova(full, test = 'Rao') #  similar to our two-way ANOVA\n\n\n\n\nSummary\n\n\n# A tibble: 2 × 2\n  p.value model     \n    <dbl> <chr>     \n1   0.927 chisq.test\n2   0.647 glm       \n\n\n\n\n\n\n\n\n\nNHST\n\n\nR code\na <- chisq.test(d_mat) # p-value > 0.05\n\n\n\n\nLinear models\n\n\nR code\nfull = glm(n ~ self_id_as_coder * sex, family = poisson(), data = d_long) # log-linear model\nb = anova(full, test = 'Rao') #  similar to our two-way ANOVA\n\n\n\n\nSummary\n\n\n# A tibble: 2 × 2\n  p.value model     \n    <dbl> <chr>     \n1  0.0235 chisq.test\n2  0.0235 glm       \n\n\n\n\n\n\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\nWarning: The `origin` argument of `stat_bin()` is deprecated as of ggplot2 2.1.0.\nℹ Please use the `boundary` argument instead.\n\n\n\n\n\n\n\n\n\nNHST\n\n\n\n\n\nLinear models\n\n\n\n\n\nSummary\n\n\n# A tibble: 3 × 5\n    p.value estimate conf.low conf.high model \n      <dbl>    <dbl>    <dbl>     <dbl> <chr> \n1 0.163        -17.9    -43.4      7.73 t.test\n2 0.0000119     NA       NA       NA    glm   \n3 0.163         NA       NA       NA    glm"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html",
    "href": "posts/sci-group-life-cycle/index.html",
    "title": "Scientific group life cycle",
    "section": "",
    "text": "Model Sketch\n\n\n\n\n\n\n\n\n\nThere are research groups \\(G\\) with a number of non-programmers \\(n\\) and programmers \\(p\\). In a data-driven world, we assume that learning to code confer a large benefit to programmers over non-programmer such that \\(\\alpha << \\beta\\). There is a constant rate of influx of students who do not know how to learn to code in research groups \\(\\mu\\). There is a cost of learning to code \\(c(p,n)\\), which depend on the number of programmers and non-programmers within group. We assume that programmers and non-programmers have different graduation rates, \\(\\nu_p\\) and \\(\\nu_n\\), with \\(\\nu_p > \\nu_n\\).\nWe model the group life cycle with the following master equation:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{n,p} &= \\mu(G_{n-1,p} - G_{n,p}) + \\nu_n \\Big((n+1)G_{n+1,p}-nG_{n,p}\\Big) \\\\\n                           &+ \\Big[ \\tau_g(n+1,p-1)(1-c(n+1, p-1)G_{n+1,p-1} - \\tau_g(n,p)G_{n,p} \\Big] \\\\\n                   &+ \\nu_p\\Big((p+1)G_{n,p+1} - pG_{n,p} \\Big) \\\\\n                   &+ \\tau_g(n+1,p)(1-c(n+1,p))G_{n+1,p}\n\\end{align*}\\]\nLearning to code confers a collective benefits on individuals \\(\\tau_g(n,p; \\alpha, \\beta) \\propto \\frac{\\bar{Z}_{n,p}}{Z_{n,p}}\\), where\n\\[\\log(Z_{n,p}) \\sim \\alpha * n + \\beta * p\\] \\[\\log(\\bar{Z}_{n,p}) \\sim \\alpha (n-1) +\\beta (c * p + (1-c)(p+1))\\]\nWe can think of \\(\\bar{Z}_{n,p}\\) as the potential benefits over \\(Z_{n,p}\\). Reorganizing the terms, we get:\n\\[\\begin{align*}\n\\log[\\tau_g(n,p; \\alpha, \\beta))] &= \\alpha (n-1) +\\beta (c * p + (1-c)(p+1)) - \\alpha * n + \\beta * p \\\\\n                                  &= -\\alpha + \\beta(1-c)\n\\end{align*}\\]\nNote that \\(\\tau_g\\) ends up being a function of \\(n, p\\) through the cost function:\n\\[c(n,p) = c_0*e^{-\\frac{p}{n}}\\]\nYou can explore both functions below:\n\n\n\n\n\n\nCost function\n\n\n\n\n\n\n\nfunction cost_prog(n, i, c_0) { return c_0 * Math.exp(-i/n); }\nfunction cost_prog2(n, i, c_0) { return c_0 * Math.exp(-i/(n+i)); }\n\nmax_gr_size = 20\nviewof N = Inputs.range([1, max_gr_size], {value: 20, step: 1, label: \"group Size\"})\nviewof coder = Inputs.range([0, (N-1)], {value: 10, step: 1, label: \"# coder\"})\nviewof c_0 = Inputs.range([0, 1], {value: 0.95, step: 0.01, label: \"c₀\"})\nviewof nc = Inputs.range([1, N], {value: (N-coder), step: 1., label: \"# non-coder\", disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nc(n,p) = c₀ * exp(-p/n)c(n,p) = c₀ * exp(-p/(n+p))\n\n\n\nnon_coder = N - coder\nxs = [...Array(N).keys()];\nys = xs.map(x => cost_prog(non_coder, x, c_0))\n\n\nPlot.lineY(ys).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ c(n,p)\", domain:[0,1] },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  =   \\(c(n,p)\\) =  (c=1 means that non-coders always fail to learn to code; c=0 means non-coders always succeed) Non-programmers can still learn to code when \\(p=0\\) because of \\(c_0\\) I woudl expect a bigger difference when we go from no prorammers in the team to one programmer\n\n\n\nx2s = [...Array(N).keys()];\ny2s = x2s.map(x => cost_prog2(non_coder, x, c_0))\n\nPlot.lineY(y2s).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ c(n,p)\", domain:[0,1] },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  =   \\(c(n,p)\\) =  (c=1 means that non-coders always fail to learn to code; c=0 means non-coders always succeed) Non-programmers can still learn to code when \\(p=0\\) because of \\(c_0\\) I woudl expect a bigger difference when we go from no prorammers in the team to one programmer\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup benefits\n\n\n\n\n\n\n\nfunction tau(n, i, alpha, beta) {\n    const c = cost_prog(n, i, 1)\n    return Math.exp(-alpha + beta*(1 - c))\n}\n\ntau_max_gr_size = 20\nviewof tau_alpha = Inputs.range([2, 4], {value: 1., step: 1, label: \"α\", format: x => 10**-x})\nviewof tau_beta = Inputs.range([1, 3], {value: 1., step: 1, label: \"β\", format: x => 10**-x})\nviewof tau_N = Inputs.range([0, tau_max_gr_size], {value: 20, step: 1, label: \"group Size\"})\nviewof tau_coder = Inputs.range([1, tau_max_gr_size], {value: 10, step: 1, label: \"# coder\"})\nviewof tau_nc = Inputs.range([1, max_gr_size], {value: (tau_N-tau_coder), step: 1., label: \"# non-coder\", disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nτ(n,p) 1\n\n\n\ntau_non_coder = tau_N - tau_coder\ntau_xs = [...Array(tau_N).keys()];\ntau_ys = tau_xs.map(x => tau(tau_non_coder, x, 10**-tau_alpha, 10**-tau_beta))\n\nPlot.lineY(tau_ys).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ τ(α,β;n,p)\" },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  ="
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#julia-model",
    "href": "posts/sci-group-life-cycle/index.html#julia-model",
    "title": "Scientific group life cycle",
    "section": "Julia model",
    "text": "Julia model\n\n\n\n\n\n\nInitialization scheme\n\n\n\n\n\nfunction initialize_u0(;N::Int=20, M::Int=20, p::Float64=0.01)\n\n  function make_draw()\n    G = zeros(N, N+1)\n    for _ in 1:N\n      n = rand(1:N)\n      i = sum(collect(rand(Binomial(1, p), N))[1]) # how many total programmers?\n      G[n, i+1] += 1 # everytime combination G[ℓ,i], count +1\n    end\n    return G\n  end\n\n  G = make_draw()\n\n  # making sure we start with zero programmers but we have varying group size\n  while sum(G[:,2:N+1]) != 0\n    G = make_draw()\n  end\n\n  G = G ./ N # normalized by tot number of groups\n\n  hm = heatmap(G, xlabel=\"# non-coders\", ylabel=\"# coders\", title=\"Frac groups with p coders and n non-coder\", c = :heat)\n\n  # ArrayPartition are nice because we can access the level such as G.x[ℓ][i]\n  return ArrayPartition(Tuple([G[n,:] for n=1:N])), hm\nend\n\nμ  = 0.001   # inflow new students-non coders\nνₙ = 0.01    # death rate non-coders\nνₚ = 0.05    # death rate coders\nα  = 0.01    # benefits non coders\nβ  = 0.1     # benefits coders\np  = [μ, νₙ, νₚ, α, β]\n\nn,M = 20, 1000\nu₀, hm = initialize_u0(N=n, M=M, p=0.01)\ntspan = (0., 4000.)\n\nhm # show p_n init mat\n\n\n\nc(n, i) = 0.95 * exp(-i / n) # cost function\nτ(n, i, α, β) = exp(-α + β*(1 - c(n, i))) # group benefits\n\nfunction life_cycle_research_groups!(du, u, p, t)\n  G, N, P = u, length(u.x), length(first(u.x)) # Note that there can be no coders but not non-coders\n  μ, νₙ, νₚ, α, β = p\n\n  for n=1:N, i=1:P\n    coder, non_coder, gr_size = i-1, n, P-1   # we distinguish indices from actual values.\n    \n    du.x[n][i] = -τ(non_coder, coder, α, β)*G.x[n][i] # 4th term\n    coder < gr_size && ( du.x[n][i] += νₚ*( (coder+1)*G.x[n][i+1] - coder*G.x[n][i] ) )  # 5th term\n    non_coder > 1 && ( du.x[n][i] += μ*(G.x[n-1][i] - G.x[n][i])  )         # 1st term\n    \n    if n < N\n      du.x[n][i] += τ(non_coder+1, coder, α, β)*(1 - c(non_coder+1, coder))*G.x[n+1][i]     # 6th term\n      du.x[n][i] += νₙ*( (non_coder+1)*G.x[n+1][i] - non_coder*G.x[n][i] )      # 2nd term\n      coder > 0 && ( du.x[n][i] += τ(non_coder+1, coder-1, α, β)*(1 - c(non_coder+1, coder-1))*G.x[n+1][i-1] ) # 3rd term \n    end\n  end\nend"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#output",
    "href": "posts/sci-group-life-cycle/index.html#output",
    "title": "Scientific group life cycle",
    "section": "Output",
    "text": "Output\n\ndata = FileAttachment(\"data.json\").json()\np = Object.keys(data).map(d => d.split(\"_\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nminmax = (p, i) => d3.extent(p.map(d => parseFloat(d[i])))\n\nviewof mu    = Inputs.range(minmax(p,0), {step: 0.03, label: \"μ\", value:\"0.0001\"})\nviewof nu_n  = Inputs.range(minmax(p,0), {step: 0.05, label: \"νₙ\", value:\"0.01\"})\nviewof nu_p  = Inputs.range(minmax(p,1), {step: 0.1,  label: \"νₚ\", value:\"0.05\"})\nviewof alpha = Inputs.range(minmax(p,2), {step: 0.15, label: \"α\", value:\"0.01\"})\nviewof beta  = Inputs.range(minmax(p,3), {step: 0.05, label: \"β\", value:\"0.1\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof myN    = Inputs.range([1,11], {step: 1, label: \"sekect N\"})\nInputs.table(data[\"0.001_0.01_0.05_0.01_0.1\"].filter(d => d.N == myN))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\n\n\n\n// f = (x) => Number.isInteger(x) ? x.toPrecision(2) : x\n// Inputs.table(data[\"0.001_0.01_0.05_0.01_0.1\"])\n\nPlot.plot({\n  x: {type:\"log\"},\n  y: {domain: [0,1]},\n  color: {scheme: \"reds\", type: \"ordinal\", legend: true},\n  marks: [\n    Plot.line(\n      data[\"0.001_0.01_0.05_0.01_0.1\"], {\n        x: 'timesteps', y: \"value\", stroke: \"N\"\n        }),\n    Plot.dot(\n      data[\"0.001_0.01_0.05_0.01_0.1\"], {\n        x: 'timesteps', y: \"value\", stroke: \"N\"\n        })\n  ]\n})"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#takeaways",
    "href": "posts/sci-group-life-cycle/index.html#takeaways",
    "title": "Scientific group life cycle",
    "section": "Takeaways:",
    "text": "Takeaways:"
  }
]