---
title: Survey modeling (early release)
subtitle: Preliminary modeling of a survey on the cost and benefits of learning to code
description: |
  The costs and benefits of learning to code in science vary across individuals and disciplines. We should have a better idea of these tradeoffs before selling anyone on coding.
categories:
  - Survey
  - Programming
  - Modeling
date: today
toc: true
highlight-style: pygments
author: Jonathan St-Onge
editor: visual
format: 
  html: 
    fig-width: 8
    fig-height: 5
    code-fold: true
---

```{r}
#| include: false
#| message: false
#| warning: false

library(here)
library(janitor)
library(tidyverse)
library(brms)
library(tidybayes)
library(scales)
library(patchwork)
library(broom.mixed)

source("helpers.R")

clrs <- MetBrewer::met.brewer("Lakota", 6)
theme_set(theme_bw())

# Seed stuff
set.seed(1234)
BAYES_SEED <- 1234

df <- readr::read_csv("data_clean.csv")

# forgotten recoded variables
df$pct_social_contacts_coding_ord <- factor(df$pct_social_contacts_coding_ord, levels = c(1,2,3))
df$pct_social_contacts_coding_c <- as.numeric(scale(df$pct_social_contacts_coding, scale = FALSE))
df$rich_soc_net_coder <- ifelse(df$pct_social_contacts_coding <= 80, 1, 0)
df$self_id_as_coder <- factor(df$self_id_as_coder, levels = c("No","Maybe","Yes"), ordered = TRUE)
df$first_line_code_before_18 <- ifelse(df$first_line_code_before_18 == "yes", 1, 0)
df$is_male <- ifelse(df$gender_binary == "male", 1, 0)
df$is_stem <- ifelse(df$dept_students_binary == "STEM", 1, 0)

coder <- subset(df, is_coder == "coder")
```

| Abbrev | Var Name | Label | Type | Is Recoded |
|---------|:-----|------:|:------:| :----: |
| S      | self_id_as_coder   |    Self Id as Coder |   Categorical/Ordinal   | | 
| G     | is_male  |   Gender |  Binary   | x |
| E       |   first_line_code_before_18  |   First line code before 18 |  Binary    | x |
| C       |   value_comp_skills_wrt_domain_ord  |  Feel Computational Skills valued wrt to Domain |  Ordinal    |  |
| SN       |   pct_social_contacts_coding  |  Proportion of social contacts who are coder |  Interval    |  |
| RSN       |   rich_soc_net_coder  |  More than 80\% of social contacts are coder |  Binary    | x |
| D       |   is_stem  | Respondent is from Stem |  Binary    | x |
: Table 1: Summary used  variables

# Logistic regression

 - [Wheiss' writeup on Bayes Rules! Ch. 13](https://bayesf22-notebook.classes.andrewheiss.com/bayes-rules/13-chapter.html#the-general-setup)


::: panel-tabset


## Model 1: E ~ RSN

```{r}

coder_log_reg <- coder %>% 
  select(pct_social_contacts_coding, first_line_code_before_18) |> 
  mutate(across(c(pct_social_contacts_coding), 
                ~scale(., scale = FALSE), .names = "{col}_centered")) |> 
  mutate(across(c(pct_social_contacts_coding), 
                ~as.numeric(scale(., scale = FALSE)), .names = "{col}_c"))

extract_attributes <- function(x) {
  attributes(x) %>%
    set_names(janitor::make_clean_names(names(.))) %>%
    as_tibble() %>%
    slice(1)
}

unscaled <- coder_log_reg %>%
  select(ends_with("_centered")) |> 
  summarize(across(everything(), ~extract_attributes(.))) |> 
  pivot_longer(everything()) |> 
  unnest(value) |> 
  split(~name)
```


::: {.callout-note collapse="true"}
## Algebraic model
```{=tex}
\begin{align*}
  \text{RSN}_i &\sim \text{Bernoulli}(\pi_i) \\
  \text{logit}(\pi_i) &= \beta_0 D_i + \beta_1 G_i
\end{align*}
```
:::

```{r}
priors <- c(prior(normal(-1.39, 0.7), class = Intercept),
            prior(normal(0.07, 0.035), class = b, coef = "pct_social_contacts_coding_c"))

model_weather_prior_brms <- brm(
  bf(first_line_code_before_18 ~ pct_social_contacts_coding_c),
  data = coder,
  family = bernoulli(link = "logit"),
  prior = priors,
  sample_prior = "only",
  chains = 4, iter = 4000, seed = BAYES_SEED, 
  backend = "cmdstanr", refresh = 0
)

p1 <- tibble(
  pct_social_contacts_coding = seq(0, 100, by = 0.1)
) |> 
  mutate(pct_social_contacts_coding_c = pct_social_contacts_coding - unscaled$pct_social_contacts_coding_centered$scaled_center) |> 
  add_epred_draws(model_weather_prior_brms, ndraws = 100) |> 
  ggplot(aes(x = pct_social_contacts_coding, y = .epred)) +
  geom_line(aes(group = .draw), alpha = 0.5, size = 0.5, color = clrs[6]) +
  labs(x = "% Social Contacts Coding", y = "Probability first line of code before 18")

p2 <- tibble(
  pct_social_contacts_coding = seq(0, 100, by = 0.1)
) |> 
  mutate(pct_social_contacts_coding_c = pct_social_contacts_coding - unscaled$pct_social_contacts_coding_centered$scaled_center) |>
  add_predicted_draws(model_weather_prior_brms, ndraws = 100) |> 
  group_by(.draw) |> 
  summarize(proportion_early_exp = mean(.prediction == 1)) |> 
  ggplot(aes(x = proportion_early_exp)) +
  geom_histogram(binwidth = 0.02, color = "white", fill = clrs[1]) +
  labs(x = "Proportion of early experience in each draw", y = "Count")

p1 | p2
```

## Model 2: RSN ~ D + G

::: {.callout-note collapse="true"}
## Algebraic model
```{=tex}
\begin{align*}
  \text{RSN}_i &\sim \text{Bernoulli}(\pi_i) \\
  \text{logit}(\pi_i) &= \beta_0 D_i + \beta_1 G_i
\end{align*}
```
:::

```{r}
# priors <- c(prior(normal(-1.39, 0.7), class = Intercept),
#             prior(normal(0.07, 0.035), class = b, coef = "humidity9am_c"))

# model_weather_prior_brms <- brm(
#   bf(raintomorrow ~ humidity9am_c),
#   data = weather,
#   family = bernoulli(link = "logit"),
#   prior = priors,
#   sample_prior = "only",
#   chains = 4, iter = 4000, seed = BAYES_SEED, 
#   backend = "cmdstanr", refresh = 0
# )
```

## Data

### APA table

```{r}

df |> count(pct_social_contacts_coding, first_line_code_before_18)
 
make_apa_table(
  coder |> 
    mutate(first_line_code_before_18 = ifelse(first_line_code_before_18 == 1, "has early exp", "no early exp")), 
    "first_line_code_before_18", 
    "pct_social_contacts_coding"
  )
```


### Plotting probs

```{r}
# logit_df <- tibble(humidity9am = seq(0, 100, length.out = 101),
#                    logits = seq(-4, 6, length.out = 101)) |> 
#   mutate(odds = exp(logits)) |> 
#   mutate(probs = plogis(logits))
```


:::


# (Ordered) logistic regression

 - [Wheiss' writeup on Statistical Rethinking Week 6](https://bayesf22-notebook.classes.andrewheiss.com/rethinking/10-video.html)

::: panel-tabset

## Model 1: S ~ G + E

::: {.callout-note collapse="true"}
## Algebraic model
```{=tex}
\begin{align*}
  y_i &\sim \text{Ordered Logit}(\phi_i, \alpha) \\
  \phi_i &= \beta_1 G_i + \beta_2 E_i \\
  B_{1,2} &\sim  \mathcal{N}(0,0.5) \\
  \alpha_k &\sim \mathcal{N}(0,1) \\
\end{align*}
```
:::

```{r}
#| warning: false
#| message: false
priors <- c(prior(normal(0, 1.5), class = Intercept))
inits <- list(Intercepts = c(-1, 0, 1.2))

model_ge <- brm(
  bf(self_id_as_coder ~ is_male + first_line_code_before_18),
  data = coder,
  family = cumulative(link = "logit"),
  prior = priors,
  init = rep(list(inits), 4),
  save_warmup = TRUE,
  chains = 4, iter = 2000, seed = BAYES_SEED, cores = 4,
  backend = "cmdstanr", refresh = 0,
  file = ".cache/model-eg"
)

model_ge

simulated_conditions <- tribble(
  ~title, ~newdata,
  "Is_Male = 0, E = 0", tibble(is_male = 0, first_line_code_before_18 = 0),
  "Is_Male = 1, E = 0", tibble(is_male = 1, first_line_code_before_18 = 0),
  "Is_Male = 0, E = 1", tibble(is_male = 0, first_line_code_before_18 = 1),
  "Is_Male = 1, E = 1", tibble(is_male = 1, first_line_code_before_18 = 1),
) |> 
  mutate(pred_plot = map2(newdata, title, ~{
    model_ge |> 
      add_predicted_draws(newdata = .x) |> 
      ungroup() |> 
      count(.prediction) |> 
      mutate(prop = n / sum(n),
             prop_nice = label_percent(accuracy = 0.1)(prop)) |> 
      ggplot(aes(x = .prediction, y = n)) +
      geom_col(aes(fill = .prediction)) +
      geom_text(aes(y = 50, label = prop_nice), color = "white", size = 2.5, 
                angle = 90, hjust = 0) +
      scale_y_continuous(labels = scales::label_comma()) +
      scale_fill_viridis_d(option = "rocket", end = 0.85, guide = "none") +
      labs(x = "Response", y = "Count", title = .y) +
      theme(plot.title = element_text(size = rel(1), hjust = 0.5))
  }))

wrap_plots(simulated_conditions$pred_plot, nrow = 2, byrow = FALSE)
```

### MASS::polr

```{r}
# 3 levels ~ 1/0 + 1/0
# same in rstanarm
logistic1 <- MASS::polr(self_id_as_coder ~ is_male + first_line_code_before_18, 
                        data = coder, Hess = TRUE)
summary(logistic1)
```

## Model 2: S ~ E + G:E

```{r}
#| warning: false
#| message: false
model_e_gender <- brm(
  bf(self_id_as_coder ~  first_line_code_before_18 + first_line_code_before_18:is_male),
  data = coder,
  family = cumulative(link = "logit"),
  prior = priors,
  init = rep(list(inits), 4),
  save_warmup = TRUE,
  chains = 4, iter = 2000, seed = BAYES_SEED, cores = 4,
  backend = "cmdstanr", refresh = 0,
  file = ".cache/model-e-gender"
)

model_e_gender

model_e_gender |> 
  spread_draws(`^b_.*`, regex = TRUE) |> 
  mutate(`b_first_line_code_before_18:is_male` = b_first_line_code_before_18 + `b_first_line_code_before_18:is_male`) |> 
  pivot_longer(starts_with("b_"), names_to = ".variable") |> 
  group_by(.variable) |> 
  summarize(avg = mean(value))
```

## Data

### APA table:  S ~ G + E

```{r}
#| warning: false
#| message: false
#| echo: false
make_apa_table(df, "gender_binary", c("first_line_code_before_18", "self_id_as_coder"))
```

### Plotting Ordinal Response

```{r}
#| warning: false
#| message: false
#| echo: false

p1 <- coder |> 
  count(self_id_as_coder) |> 
  mutate(pr_k = n / sum(n),
         cum_pr_k = cumsum(pr_k)) |> 
  ggplot(aes(x = self_id_as_coder, y = cum_pr_k)) +
  geom_line(aes(group = 0), color = clrs[2], size = 1) +
  geom_point(shape = 21, fill = clrs[2], color = "white", size = 5, stroke = 1) +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(x = "Response", y = "Cumulative proportion")

p2 <- coder |> 
  count(self_id_as_coder) |> 
  mutate(pr_k = n / sum(n),
         cum_pr_k = cumsum(pr_k)) |> 
  mutate(alpha_k = qlogis(cum_pr_k)) |> 
  ggplot(aes(x = self_id_as_coder, y = alpha_k)) +
  geom_line(aes(group = 0), size = 1, color = clrs[1]) +
  geom_point(shape = 21, fill = clrs[1], color = "white", size = 5, stroke = 1) +
  labs(x = "Response", y = "Log cumulative odds")

p1 | p2 
```

:::

